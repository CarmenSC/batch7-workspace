{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66f2958",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3bf24e7ba2c45b1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU02 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd525da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.034238Z",
     "start_time": "2024-02-01T00:29:46.883477Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bebba7f87f4f151b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib # for grading\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2b87c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a23783765364606a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Read the Oscars data (graded)\n",
    "\n",
    "In this first exercise, we aim to create a single dataframe, combining all Oscar nominees from all ceremonies.\n",
    "\n",
    "With a caveat though: **we want to include seasons from the year 1960 onwards**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e539f29e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.270327Z",
     "start_time": "2024-02-01T00:29:49.038564Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e16abeb47fc4ea37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_year(folder_path, file_name):\n",
    "    path = os.path.join(folder_path, file_name)\n",
    "    return pd.read_csv(path, index_col = 0)\n",
    "\n",
    "def read_nominees(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    # Create a list with the name of all files containing annual nominees from\n",
    "    # 1960 inclusive and onwards (just the filename, no complete path.)\n",
    "    # files_from_1960: List[str] = ...\n",
    "    # YOUR CODE HERE\n",
    "    files_from_1960: List[str] =[file for file in os.listdir(folder_path) if int(file[0:4])>=1960]\n",
    "\n",
    "    # Create a list with the dataframes\n",
    "    # nominees_year: List[pd.DataFrame] = ...\n",
    "    # YOUR CODE HERE\n",
    "    nominees_year: List[pd.DataFrame] =  [read_year(folder_path, file) for file in files_from_1960]\n",
    "        \n",
    "    # Use pd.concat to create a single dataframe.\n",
    "    # nominees: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    nominees: pd.DataFrame =  pd.concat(nominees_year, ignore_index=True)\n",
    "    # Drop the column 'ceremony'.\n",
    "    # nominees = ...\n",
    "    # YOUR CODE HERE\n",
    "    nominees = nominees.drop(columns=['ceremony'])\n",
    "    \n",
    "    ## Remove missing values.\n",
    "    # nominees = ...\n",
    "    # YOUR CODE HERE\n",
    "    nominees = nominees.dropna()\n",
    "    return nominees\n",
    "\n",
    "\n",
    "nominees = read_nominees(os.path.join('data', 'oscars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5b3ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.290742Z",
     "start_time": "2024-02-01T00:29:49.275518Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2656708135a5a5e4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert nominees['year_ceremony'].min() == 1960\n",
    "assert nominees['year_ceremony'].max() == 2023\n",
    "assert nominees.isna().sum().sum() == 0\n",
    "assert nominees.shape == (7116, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31920670",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3383047fa18f453e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Read the IMDB Ratings data (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f86c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.331880Z",
     "start_time": "2024-02-01T00:29:49.300944Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e228c2d82463c6b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_ratings(file_path): \n",
    "    # Read the ratings data and drop the 'director', 'star1', 'star2', 'star3', and 'star4' columns.\n",
    "    # top_rated: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    top_rated: pd.DataFrame = pd.read_csv(file_path)\n",
    "        \n",
    "    columns_to_drop = ['director', 'star1', 'star2', 'star3', 'star4']\n",
    "    top_rated = top_rated.drop(columns=columns_to_drop)\n",
    "        \n",
    "    # Please make the necessary changes and convert the 'runtime' column to int\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    top_rated['runtime'] = top_rated['runtime'].str.replace(' min', '').astype(int)    \n",
    "    ## Remove the lines with no metascore info.\n",
    "    # YOUR CODE HERE\n",
    "    top_rated = top_rated.dropna(subset=['metascore'])\n",
    "    \n",
    "    return top_rated\n",
    "\n",
    "top_rated = read_ratings(os.path.join('data','imdb_top_1000.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e0b5f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.345106Z",
     "start_time": "2024-02-01T00:29:49.335490Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d21007e725ab889",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_rated.shape == (843, 5)\n",
    "assert top_rated.runtime.min() == 64\n",
    "assert top_rated.runtime.max() == 321\n",
    "assert top_rated.metascore.isna().sum() == 0\n",
    "assert set(top_rated.columns) == set([\n",
    "    'film', 'metascore', 'no_votes', 'rating', 'runtime'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6c904",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ae195e6dd100fc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Combine Oscars and Ratings data (graded)\n",
    "\n",
    "Let's combine both dataframes into a single dataset, using an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b12dc70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.372911Z",
     "start_time": "2024-02-01T00:29:49.355137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['year_film', 'year_ceremony', 'category', 'name', 'film', 'winner'], dtype='object'),\n",
       " Index(['film', 'runtime', 'rating', 'metascore', 'no_votes'], dtype='object'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominees.columns, top_rated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a56101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.395200Z",
     "start_time": "2024-02-01T00:29:49.376702Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a65f1464b4525a8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember that you want use a column of both dataframes to combine them.\n",
    "# Join only the nominees of films present on the ratings list\n",
    "# best_rated_nominees = ...\n",
    "# YOUR CODE HERE\n",
    "best_rated_nominees: pd.DataFrame = pd.merge(nominees, top_rated, how='inner', on='film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26483891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.412391Z",
     "start_time": "2024-02-01T00:29:49.404869Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ac9aef3d5251e36c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert best_rated_nominees.shape == (1919, 10)\n",
    "assert set(best_rated_nominees.columns) == set(['year_film', 'year_ceremony', 'category', 'name', 'film', 'winner',\n",
    "       'runtime', 'rating', 'metascore', 'no_votes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271ecf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1fd4cd11d5139889",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4 Read top grossing and budget films data (graded)\n",
    "\n",
    "We will read the two remaining pieces of data. \n",
    "\n",
    "Again, albeit the step-by-step description, we encourage you to use method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb533fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.441589Z",
     "start_time": "2024-02-01T00:29:49.417200Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-503e208490ff38e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_gross(file_path):\n",
    "    # Read the works data.\n",
    "    # top_grossing: pd.DataFrame = ...\n",
    "        # Remove the year column.\n",
    "    # gross: pd.DataFrame = ...\n",
    "\n",
    "    ## Ensure that the gross data is read as int.\n",
    "     # top_grossing: pd.DataFrame = ...\n",
    "      # YOUR CODE HERE\n",
    "    top_grossing = (pd.read_csv(file_path)\n",
    "                    # Ensure that the 'gross' data is read as int\n",
    "                    .assign(gross=lambda df: df['gross'].str.replace(',', '').astype(int))\n",
    "                    # Remove the 'year' column\n",
    "                    .drop(columns=['year'])\n",
    "                    )\n",
    "    return top_grossing\n",
    "\n",
    "\n",
    "def read_budget(file_path):\n",
    "    # Read the top budget data and drop the 'runtime', 'theaters', and 'year' Columns\n",
    "\n",
    "    ## Please make the necessary changes and convert the 'budget_rank' column to int\n",
    "    # YOUR CODE HERE\n",
    "    top_budget = (pd.read_csv(file_path)\n",
    "                  .drop(columns=['runtime', 'theaters', 'year'])\n",
    "                  # Remove non-numeric characters and convert 'budget_rank' to int\n",
    "                  .assign(budget_rank=lambda df: df['budget_rank'].str.replace('#', '').astype(int))\n",
    "                  )\n",
    "    return top_budget\n",
    "\n",
    "\n",
    "top_grossing = read_gross('data/gross_top_200.csv')\n",
    "top_budget = read_budget('data/budget_top_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f60f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.480186Z",
     "start_time": "2024-02-01T00:29:49.457519Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b8389314995f18ea",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_grossing.shape == (200, 3)\n",
    "assert set(top_grossing.columns) == set([\n",
    "    'gross_rank', 'film', 'gross'\n",
    "])\n",
    "\n",
    "assert top_budget.shape == (500, 3)\n",
    "assert set(top_budget.columns) == set([\n",
    "   'budget_rank', 'film', 'production_cost'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839081fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c16e4e26e68cd019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5 Combine the top grossing and budget films\n",
    "\n",
    "Like we did for Oscar nominees and top rated films, now we combine the top budget and grossing films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfae5297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.504393Z",
     "start_time": "2024-02-01T00:29:49.487271Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-08d9a086cc5646cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine both dataframes, again using an inner type of join\n",
    "# top_grossing_budget : pd.DataFrame = ....\n",
    "# YOUR CODE HERE\n",
    "def combine_grossing_and_budget(grossing_df, budget_df):\n",
    "    # Combine dataframes using an inner join\n",
    "    top_grossing_budget = pd.merge(grossing_df, budget_df, how='inner', on='film')\n",
    "    \n",
    "    return top_grossing_budget\n",
    "\n",
    "\n",
    "top_grossing_budget = combine_grossing_and_budget(top_grossing, top_budget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7184d4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.517909Z",
     "start_time": "2024-02-01T00:29:49.508757Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4d9f103dfffd311b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_grossing_budget.shape == (129, 5)\n",
    "assert set(top_grossing_budget.columns) == set(\n",
    "    [\n",
    "        'budget_rank', 'film', 'production_cost', 'gross_rank', 'gross'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddd282",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab79800d6e447f1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 6 Combine everything (graded)\n",
    "\n",
    "The final goal here is to create a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f167ab69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.534288Z",
     "start_time": "2024-02-01T00:29:49.522444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['year_film', 'year_ceremony', 'category', 'name', 'film', 'winner',\n",
       "        'runtime', 'rating', 'metascore', 'no_votes'],\n",
       "       dtype='object'),\n",
       " Index(['gross_rank', 'film', 'gross', 'budget_rank', 'production_cost'], dtype='object'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rated_nominees.columns, top_grossing_budget.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b11400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.553169Z",
     "start_time": "2024-02-01T00:29:49.539257Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_common_columns(df1, df2):\n",
    "    \"\"\"\n",
    "    Identify common columns in two dataframes.\n",
    "\n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): The first dataframe.\n",
    "    df2 (pd.DataFrame): The second dataframe.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of common column names.\n",
    "    \"\"\"\n",
    "    # Get the set of columns for each dataframe\n",
    "    columns_df1 = set(df1.columns)\n",
    "    columns_df2 = set(df2.columns)\n",
    "\n",
    "    # Find the intersection (common columns) between the two sets\n",
    "    common_columns = list(columns_df1.intersection(columns_df2))\n",
    "\n",
    "    return common_columns\n",
    "\n",
    "# Usage example:\n",
    "# common_cols = get_common_columns(dataframe1, dataframe2)\n",
    "# print(common_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4eee72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.574711Z",
     "start_time": "2024-02-01T00:29:49.557742Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce1f05022e8cd63a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine best_rated_nominees and nyp into a single dataframe.\n",
    "# You need to figure out the common column shared between the two dataframes\n",
    "# top_films = ...\n",
    "# YOUR CODE HERE\n",
    "def combine_all_dataframes(rated_nominees_df, grossing_budget_df):\n",
    "    # Combine dataframes using an inner join\n",
    "    top_films = pd.merge(rated_nominees_df, grossing_budget_df, how='inner', on='film')\n",
    "    \n",
    "    return top_films\n",
    "\n",
    "\n",
    "top_films = combine_all_dataframes(best_rated_nominees, top_grossing_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c7dc60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.593750Z",
     "start_time": "2024-02-01T00:29:49.580414Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ce29fa3aec1c244e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_films.shape == (184, 14)\n",
    "assert set(top_films.columns) == set(\n",
    "    [\n",
    "       'year_film', 'year_ceremony', 'category', 'name', 'film', 'winner',\n",
    "       'runtime', 'rating', 'metascore', 'no_votes', 'budget_rank',\n",
    "       'production_cost', 'gross_rank', 'gross'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c7125",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4407d9518b0d6e2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 7 Final transformations (graded)\n",
    "\n",
    "Now, we perform the train-test split.\n",
    "\n",
    "We also perform some final transformations on both datasets:\n",
    "\n",
    "* Tranform \"winner\" into a binary feature\n",
    "* Create a new feature, rating_rank, from the rating column. \n",
    "* Filter out the movies that appear less than 10 times in the DataFrame.\n",
    "* Keep only 'film', 'winner', 'category', 'runtime', 'rating', 'metascore', 'no_votes', 'budget_rank', 'production_cost', 'gross_rank', 'rating_rank' and 'gross' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d5094ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.622361Z",
     "start_time": "2024-02-01T00:29:49.599740Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c1ab0d912e615ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_winner(df):\n",
    "    df = df.copy()\n",
    "    # df = ...\n",
    "    # YOUR CODE HERE\n",
    "    df['winner'] = df['winner'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "    return df\n",
    "\n",
    "def create_rating_rank(df):\n",
    "    df = df.copy()\n",
    "    # df['rating_rank'] = \n",
    "    # YOUR CODE HERE\n",
    "    df['rating_rank'] = df['rating'].rank(ascending=True)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # You should follow these exact steps:\n",
    "    #   1 - Binarize 'winner'\n",
    "    #   2 - Filter out rows that have a film that appear is less than 10 times in the DataFrame.\n",
    "    #   3 - Keep only the 'film', 'winner', category', 'runtime', 'rating', 'metascore', 'no_votes', \n",
    "    #      'budget_rank', 'production_cost', 'gross_rank', 'rating_rank' and 'gross' columns\n",
    "    #   5 - Create a new feature, rating_rank, from the ranking column. \n",
    "    #   6 - Sort the DataFrame by 'rating' in ascending order\n",
    "    # YOUR CODE HERE\n",
    "    df = df.copy()\n",
    "\n",
    "    # Binarize 'winner'\n",
    "    df = transform_winner(df)\n",
    "\n",
    "    # Filter out rows that have a film that appears less than 10 times\n",
    "    film_count = df['film'].value_counts()\n",
    "    df = df[df['film'].isin(film_count.index[film_count >= 10])]\n",
    "\n",
    "    # Keep only the specified columns\n",
    "    columns_to_keep = ['film', 'winner', 'category', 'runtime', 'rating', 'metascore', \n",
    "                       'no_votes', 'budget_rank', 'production_cost', 'gross_rank', \n",
    "                       'gross']\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Create 'rating_rank' and sort by 'rating'\n",
    "    df = create_rating_rank(df).sort_values('rating', ascending=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "top_films_preprocessed = preprocess_data(top_films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee21e1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.655174Z",
     "start_time": "2024-02-01T00:29:49.634229Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d9c75c48e4eaf63",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_films_preprocessed.shape == (59, 12)\n",
    "assert set(top_films_preprocessed.columns) == {\n",
    "       'category', 'film', 'runtime', 'rating', 'metascore', 'no_votes',\n",
    "       'budget_rank', 'production_cost', 'gross_rank', 'gross', 'rating_rank','winner'\n",
    "}\n",
    "assert top_films_preprocessed.budget_rank.min() == 49\n",
    "assert top_films_preprocessed.gross_rank.max() == 180\n",
    "assert top_films_preprocessed.iloc[0].no_votes == 769145"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4918d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4557c57da6142038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The house prices dataset\n",
    "\n",
    "A dataset containing several characteristics of several houses and their selling price \n",
    "\n",
    "* LotFrontage: Linear feet of street connected to property\n",
    "* LotArea: Lot size in square feet\n",
    "* OverallQual: Rates the overall material and finish of the house\n",
    "       10  Very Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* OverallCond: Rates the overall condition of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\t\n",
    "       5\tAverage\n",
    "       4\tBelow Average\t\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* MasVnrArea: Masonry veneer area in square feet\n",
    "* BsmtFinSF1: Type 1 finished square feet\n",
    "* BsmtUnfSF: Unfinished square feet of basement area\n",
    "* TotalBsmtSF: Total square feet of basement area\n",
    "* 1stFlrSF: First Floor square feet\n",
    "* 2ndFlrSF: Second floor square feet\n",
    "* LowQualFinSF: Low quality finished square feet (all floors)\n",
    "* GrLivArea: Above grade (ground) living area square feet\n",
    "* BsmtFullBath: Basement full bathrooms\n",
    "* BsmtHalfBath: Basement half bathrooms\n",
    "* FullBath: Full bathrooms above grade\n",
    "* HalfBath: Half baths above grade\n",
    "* BedroomAbvGr: Bedrooms above grade (does NOT include basement bedrooms)\n",
    "* KitchenAbvGr: Kitchens above grade\n",
    "* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "* Fireplaces: Number of fireplaces\n",
    "* GarageCars: Size of garage in car capacity\n",
    "* GarageArea: Size of garage in square feet\n",
    "* WoodDeckSF: Wood deck area in square feet\n",
    "* OpenPorchSF: Open porch area in square feet\n",
    "* EnclosedPorch: Enclosed porch area in square feet\n",
    "* 3SsnPorch: Three season porch area in square feet\n",
    "* ScreenPorch: Screen porch area in square feet\n",
    "* PoolArea: Pool area in square feet\n",
    "* MiscVal: $Value of miscellaneous feature \n",
    "* SellingDate: Date when the house was sold\n",
    "* BuildingDate: Date when the house was built\n",
    "* RemodAddDate: Remodel date (same as construction date if no remodeling or additions)\n",
    "* SalePrice: The house price at the selling date (our target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd8c63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f274d778f5887e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's read the csv and create our train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "049fd662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.717356Z",
     "start_time": "2024-02-01T00:29:49.668848Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7582e93ac7adb85f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def house_price_dataset():\n",
    "    return pd.read_csv(\n",
    "    'data/housePrices.csv', \n",
    "        parse_dates=[\n",
    "            'SellingDate',\n",
    "            'BuildingDate',\n",
    "            'RemodAddDate'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "dataset = house_price_dataset()\n",
    "dataset_train, dataset_test = train_test_split(dataset, random_state=0)\n",
    "X_train = dataset_train.drop(columns='SalePrice')\n",
    "y_train = dataset_train.SalePrice\n",
    "X_test = dataset_test.drop(columns='SalePrice')\n",
    "y_test = dataset_test.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa1fe4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-425695b0c9d45ae9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 8 Build a DateTransformer transformer (graded)\n",
    "\n",
    "A simple transformer that transforms dates into timedeltas can be useful, from times to times, when modeling. Usually when you have features that are Dates you compute a time delta between the feature and a given refence date.\n",
    "\n",
    "e.g Imagine that your clients have a loyalty period that ends at a given date. When your model is doing some predictions, one of the features that you can use is the number of days until the end of the loyalty period. i.e the date when the loyalty ends minus the date when your model is running. \n",
    "\n",
    "In the house prices dataset, the selling date will be the reference data, since we want to predict the house price at the selling date. For instance, two houses with the exact same features can vary in prices if the construction year is different. So we should input this information and feed into the model. Then we need to convert the other dates using our transformer\n",
    "\n",
    "Hint: Result should be integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43b78c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.732114Z",
     "start_time": "2024-02-01T00:29:49.723282Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9538038181ba578",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "#    # Implement the __init__ method.\n",
    "#    # Our DateTransformer must be able to receive two parameters: \n",
    "#    # datetime_cols: a list, that contains the datetime cols that should be converted\n",
    "#    # ref_date_col: indicates the name of the column that should be used as reference date,\n",
    "#    # YOUR CODE HERE\n",
    "#    def __init__(self, datetime_cols: List[str], ref_date_col: str) -> None:\n",
    "#        # Initialize with datetime columns and reference date column\n",
    "#        self.datetime_cols = datetime_cols\n",
    "#        self.ref_date_col = ref_date_col\n",
    "#        \n",
    "#    # There's no need for a fit method in this case, it does nothing.\n",
    "#    # We should be able to call fit without any explicit parameters.\n",
    "#    # Meaning: we should be able to call fit() on the transformer.\n",
    "#    # YOUR CODE HERE\n",
    "#    def fit(self, X: pd.DataFrame, y=None)-> None:\n",
    "#        # Fit does nothing in this case, just returns self\n",
    "#        return self\n",
    "#\n",
    "#    # Transform should transform all datetime columns into the difference in days to the reference date.\n",
    "#    # The reference date column should be dropped. \n",
    "#    # YOUR CODE HERE\n",
    "#    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "#        # Ensure working on a copy of the data to avoid altering original dataframe\n",
    "#        X_transformed = X.copy()\n",
    "#\n",
    "#        # Check if the reference date column exists\n",
    "#        if self.ref_date_col not in X_transformed.columns:\n",
    "#            raise ValueError(f\"Reference date column '{self.ref_date_col}' not found in the dataframe.\")\n",
    "#\n",
    "#        # Convert each datetime column to timedelta in days relative to the reference date\n",
    "#        for col in self.datetime_cols:\n",
    "#            if col not in X_transformed.columns:\n",
    "#                raise ValueError(f\"Column '{col}' not found in the dataframe.\")\n",
    "#\n",
    "#            X_transformed[col] = (X_transformed[self.ref_date_col] - X_transformed[col]).dt.days\n",
    "#        \n",
    "#        # Drop the reference date column\n",
    "#        X_transformed.drop(columns=[self.ref_date_col], inplace=True)\n",
    "#\n",
    "#        # Convert to int64\n",
    "#        for col in self.datetime_cols:\n",
    "#            X_transformed[col] = X_transformed[col].astype(np.int64)\n",
    "#\n",
    "#        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fd4008a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.753815Z",
     "start_time": "2024-02-01T00:29:49.737555Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Implement the __init__ method.\n",
    "    # Our DateTransformer must be able to receive two parameters: \n",
    "    # datetime_cols: a list, that contains the datetime cols that should be converted\n",
    "    # ref_date_col - indicates the name of the column that should be used as reference date,\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    def __init__(self, datetime_cols: List[str], ref_date_col: str) -> None:\n",
    "        self.datetime_cols = datetime_cols\n",
    "        self.ref_date_col = ref_date_col\n",
    "        \n",
    "        \n",
    "    # There's no need for a fit method in this case, it does nothing.\n",
    "    # We should be able to call fit without any explicit parameters.\n",
    "    # Meaning: we should be able to call transformer.fit().\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    def fit(self, X: pd.DataFrame, y=None)-> None:\n",
    "        return self\n",
    "\n",
    "    # Transform should transform all datetime columns into the difference in days to the reference date.\n",
    "    # The reference date column should be dropped. \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()\n",
    "        for datetime_col in self.datetime_cols:\n",
    "            X[datetime_col] = (pd.to_datetime(X[datetime_col]) - pd.to_datetime(X[self.ref_date_col])).dt.days.astype(int)\n",
    "        return X.drop(self.ref_date_col, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bab1d26c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.781581Z",
     "start_time": "2024-02-01T00:29:49.759538Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b64b26753ecd8561",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = DateTransformer(\n",
    "    datetime_cols=['BuildingDate', 'RemodAddDate'], \n",
    "    ref_date_col='SellingDate'\n",
    ").fit_transform(X_train)\n",
    "assert X_train_transformed.BuildingDate.min() == -49008\n",
    "assert X_train_transformed.BuildingDate.max() == -1\n",
    "assert 'SellingDate' not in X_train_transformed.columns\n",
    "assert X_train_transformed.dtypes.BuildingDate == np.dtype('int64')\n",
    "assert X_train_transformed.dtypes.RemodAddDate == np.dtype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc7b15",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5989c2b51d38b449",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You might be wondering why we have to implement it as a Transformer Class, and not using functions.\n",
    "You'll understand the reason in the next section, we're we can tie them all together in a `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714780de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46fe8c71f80d2717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 9 Building the pipeline (graded)\n",
    "\n",
    "Finally, we want to use the two transformers together and run a linear regression on top. We want to:\n",
    "\n",
    "* Convert the dates to time deltas relative to the Selling Date.\n",
    "\n",
    "* Scale all features to the same range, using `sklearn.preprocessing.RobustScaler()`.\n",
    "\n",
    "* Estimate the SellingPrice using a Linear Regression.\n",
    "\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data (i.e., Gaussian with zero mean and unit variance).\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "697faf63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.917567Z",
     "start_time": "2024-02-01T00:29:49.787661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>SellingDate</th>\n",
       "      <th>BuildingDate</th>\n",
       "      <th>RemodAddDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.516651</td>\n",
       "      <td>10165.033302</td>\n",
       "      <td>6.095147</td>\n",
       "      <td>5.594672</td>\n",
       "      <td>102.087536</td>\n",
       "      <td>564.330162</td>\n",
       "      <td>1046.601332</td>\n",
       "      <td>1159.809705</td>\n",
       "      <td>351.509039</td>\n",
       "      <td>6.424358</td>\n",
       "      <td>...</td>\n",
       "      <td>97.315890</td>\n",
       "      <td>44.084681</td>\n",
       "      <td>21.963844</td>\n",
       "      <td>3.058991</td>\n",
       "      <td>15.811608</td>\n",
       "      <td>2.394862</td>\n",
       "      <td>28.690771</td>\n",
       "      <td>2007-11-05 04:29:54.862035968</td>\n",
       "      <td>1970-06-04 20:34:28.886774500</td>\n",
       "      <td>1984-04-20 15:15:14.557564224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1491.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>1875-11-01 00:00:00</td>\n",
       "      <td>1950-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>792.500000</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2007-01-04 00:00:00</td>\n",
       "      <td>1953-01-11 00:00:00</td>\n",
       "      <td>1967-01-03 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>9505.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>1077.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008-01-05 00:00:00</td>\n",
       "      <td>1972-01-09 00:00:00</td>\n",
       "      <td>1992-01-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>11635.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1282.500000</td>\n",
       "      <td>1382.500000</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2009-01-06 00:00:00</td>\n",
       "      <td>1999-01-07 00:00:00</td>\n",
       "      <td>2003-01-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>182.000000</td>\n",
       "      <td>115149.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>3200.000000</td>\n",
       "      <td>3228.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>2010-01-07 00:00:00</td>\n",
       "      <td>2009-01-12 00:00:00</td>\n",
       "      <td>2010-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.228422</td>\n",
       "      <td>6319.536187</td>\n",
       "      <td>1.365732</td>\n",
       "      <td>1.120939</td>\n",
       "      <td>179.723470</td>\n",
       "      <td>442.621653</td>\n",
       "      <td>418.210100</td>\n",
       "      <td>380.318077</td>\n",
       "      <td>437.579545</td>\n",
       "      <td>52.580304</td>\n",
       "      <td>...</td>\n",
       "      <td>124.988613</td>\n",
       "      <td>62.975199</td>\n",
       "      <td>60.397025</td>\n",
       "      <td>27.657847</td>\n",
       "      <td>56.470192</td>\n",
       "      <td>39.015517</td>\n",
       "      <td>190.231875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LotFrontage        LotArea  OverallQual  OverallCond   MasVnrArea  \\\n",
       "count  1051.000000    1051.000000  1051.000000  1051.000000  1051.000000   \n",
       "mean     56.516651   10165.033302     6.095147     5.594672   102.087536   \n",
       "min       0.000000    1491.000000     1.000000     2.000000     0.000000   \n",
       "25%      40.000000    7500.000000     5.000000     5.000000     0.000000   \n",
       "50%      61.000000    9505.000000     6.000000     5.000000     0.000000   \n",
       "75%      78.000000   11635.000000     7.000000     6.000000   161.000000   \n",
       "max     182.000000  115149.000000    10.000000     9.000000  1600.000000   \n",
       "std      33.228422    6319.536187     1.365732     1.120939   179.723470   \n",
       "\n",
       "         BsmtUnfSF  TotalBsmtSF     1stFlrSF     2ndFlrSF  LowQualFinSF  ...  \\\n",
       "count  1051.000000  1051.000000  1051.000000  1051.000000   1051.000000  ...   \n",
       "mean    564.330162  1046.601332  1159.809705   351.509039      6.424358  ...   \n",
       "min       0.000000     0.000000   334.000000     0.000000      0.000000  ...   \n",
       "25%     217.500000   792.500000   876.000000     0.000000      0.000000  ...   \n",
       "50%     463.000000   990.000000  1077.000000     0.000000      0.000000  ...   \n",
       "75%     808.000000  1282.500000  1382.500000   736.000000      0.000000  ...   \n",
       "max    2336.000000  3200.000000  3228.000000  2065.000000    572.000000  ...   \n",
       "std     442.621653   418.210100   380.318077   437.579545     52.580304  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1051.000000  1051.000000    1051.000000  1051.000000  1051.000000   \n",
       "mean     97.315890    44.084681      21.963844     3.058991    15.811608   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    24.000000       0.000000     0.000000     0.000000   \n",
       "75%     177.500000    64.500000       0.000000     0.000000     0.000000   \n",
       "max     728.000000   547.000000     386.000000   508.000000   480.000000   \n",
       "std     124.988613    62.975199      60.397025    27.657847    56.470192   \n",
       "\n",
       "          PoolArea      MiscVal                    SellingDate  \\\n",
       "count  1051.000000  1051.000000                           1051   \n",
       "mean      2.394862    28.690771  2007-11-05 04:29:54.862035968   \n",
       "min       0.000000     0.000000            2006-01-01 00:00:00   \n",
       "25%       0.000000     0.000000            2007-01-04 00:00:00   \n",
       "50%       0.000000     0.000000            2008-01-05 00:00:00   \n",
       "75%       0.000000     0.000000            2009-01-06 00:00:00   \n",
       "max     738.000000  3500.000000            2010-01-07 00:00:00   \n",
       "std      39.015517   190.231875                            NaN   \n",
       "\n",
       "                        BuildingDate                   RemodAddDate  \n",
       "count                           1051                           1051  \n",
       "mean   1970-06-04 20:34:28.886774500  1984-04-20 15:15:14.557564224  \n",
       "min              1875-11-01 00:00:00            1950-01-01 00:00:00  \n",
       "25%              1953-01-11 00:00:00            1967-01-03 00:00:00  \n",
       "50%              1972-01-09 00:00:00            1992-01-12 00:00:00  \n",
       "75%              1999-01-07 00:00:00            2003-01-05 00:00:00  \n",
       "max              2009-01-12 00:00:00            2010-01-04 00:00:00  \n",
       "std                              NaN                            NaN  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0afe11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.977700Z",
     "start_time": "2024-02-01T00:29:49.922336Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bc09de5e71383d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20737.06019314779\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline including:\n",
    "#   1 - 'date_converter', DateTransformer(['BuildingDate', 'RemodAddDate'], ref_date_col='SellingDate')\n",
    "#   2 - 'robust_scaler', RobustScaler() with the default parameters\n",
    "#   3 - 'model', LinearRegression\n",
    "# YOUR CODE HERE\n",
    "pipeline = Pipeline(\n",
    "        [\n",
    "        ('date_converter', DateTransformer(datetime_cols=['BuildingDate', 'RemodAddDate'], ref_date_col='SellingDate')),\n",
    "        ('robust_scaler', RobustScaler()),\n",
    "        ('model', LinearRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: {}'.format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01715551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:49.991950Z",
     "start_time": "2024-02-01T00:29:49.982486Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5d21dcdd34a13d24",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(pipeline) == Pipeline\n",
    "assert type(pipeline.named_steps['date_converter']) == DateTransformer\n",
    "assert type(pipeline.named_steps['robust_scaler']) == RobustScaler\n",
    "assert pipeline.named_steps['date_converter'].get_params()['ref_date_col'] == 'SellingDate'\n",
    "assert set(\n",
    "    pipeline.named_steps['date_converter'].get_params()['datetime_cols']\n",
    ") == {'BuildingDate', 'RemodAddDate'}\n",
    "assert type(pipeline.named_steps['model']) == LinearRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97367e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-154280375c499868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 10. Access the cofficients from the pipeline (ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f0738",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a913e812dcb37ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we would want to obtain the coefficients from the model to understand features with the most predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6404b9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:50.003812Z",
     "start_time": "2024-02-01T00:29:49.997503Z"
    },
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58083ef8ab8d97c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#coefs = ....\n",
    "# YOUR CODE HERE\n",
    "coefs = pipeline.named_steps['model'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8810e2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T00:29:50.015219Z",
     "start_time": "2024-02-01T00:29:50.008548Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f42cbedb988b6aa8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert coefs.shape == (30,), 'Wrong number of coefficients. Did you select the features correctly?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3facfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57f2ca220627e218",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Exercises complete, congratulations! You are about to become a certified data wrangler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
